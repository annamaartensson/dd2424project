{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annamaartensson/dd2424project/blob/issue%2F2b/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cpTRhWbe5_oh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('prideandprejudice.txt', 'https://www.gutenberg.org/cache/epub/42671/pg42671.txt')\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znWk0L0lUW0X",
        "outputId": "da046590-a3fc-4c0b-f4e9-2f7502d0536f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/cache/epub/42671/pg42671.txt\n",
            "725256/725256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = sorted(set(text))\n",
        "ids_to_chars =\n",
        "chars_to_ids ="
      ],
      "metadata": {
        "id": "PkI1dzQAUwgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "517638f4-e64c-44bf-cda0-f48d4773ad2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-e6e1477f096c>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e6e1477f096c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ids_to_chars =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "sE6UiXiA41_c"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "\n",
        "  class Grads:\n",
        "\n",
        "    def __init__(self, m, K):\n",
        "      self.b = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "      self.c = tf.Variable(tf.zeros_initializer()(shape = (K)))\n",
        "      self.U = tf.Variable(tf.zeros_initializer()(shape = (m, K)))\n",
        "      self.W = tf.Variable(tf.zeros_initializer()(shape = (m, m)))\n",
        "      self.V = tf.Variable(tf.zeros_initializer()(shape = (K, m)))\n",
        "\n",
        "    def compute(self):\n",
        "      pass\n",
        "\n",
        "  def __init__(self, seq_length, m, K, sig):\n",
        "    self.seq_length = seq_length\n",
        "    self.m = m\n",
        "    self.K = K\n",
        "    self.b = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "    self.c = tf.Variable(tf.zeros_initializer()(shape = (K)))\n",
        "    self.U = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (m, K)))\n",
        "    self.W = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (m, m)))\n",
        "    self.V = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (K, m)))\n",
        "    self.h0 = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "\n",
        "  def forwardPass(self, X, Y):\n",
        "      P = tf.Variable(tf.zeros_initializer()(shape = (self.K, self.seq_length)))\n",
        "      H = tf.Variable(tf.zeros_initializer()(shape = (self.m, self.seq_length+1)))\n",
        "      A = tf.Variable(tf.zeros_initializer()(shape = (self.m, self.seq_length)))\n",
        "      H[:,0].assign(self.h0)\n",
        "      for t in range(self.seq_length):\n",
        "        A[:,t].assign(tf.tensordot(self.W, H[:,t], 1) + tf.tensordot(self.U, X[:,t], 1) + self.b)\n",
        "        H[:,t+1].assign(tf.math.tanh(A[:,t]))\n",
        "        P[:,t].assign(tf.raw_ops.Softmax(logits = (tf.tensordot(self.V, H[:,t+1], 1) + self.c)))\n",
        "      return P, H, A\n",
        "\n",
        "  def backwardPass(self, X, Y, P, H, A):\n",
        "    grads = RNN.Grads(self.m, self.K)\n",
        "\n",
        "    G = tf.transpose(Y-P) * -1\n",
        "\n",
        "    #dL/dc\n",
        "    grads.c.assign(tf.reduce_sum(G, axis=0))\n",
        "\n",
        "    #dL/dV\n",
        "    for i in range(self.seq_length):\n",
        "      grads.V.assign(grads.V+tf.tensordot(G[i,:],H[:,i],0))\n",
        "\n",
        "    #dL/dh and dL/da, in grad_H and grad_A each row represents a timestep\n",
        "    grad_H = tf.Variable(tf.zeros_initializer()(shape = (self.seq_length, self.m)))\n",
        "    grad_A = tf.Variable(tf.zeros_initializer()(shape = (self.seq_length, self.m)))\n",
        "    grad_H[-1,:].assign(tf.tensordot(tf.reshape(G[-1,:], (1,-1)),self.V,1))\n",
        "    for i in range(self.seq_length):\n",
        "      grad_A[-i,:].assign(tf.tensordot(tf.reshape(grad_H[-i,:],(1,-1)),tf.linalg.diag(tf.ones(self.m)-tf.math.square(tf.math.tanh(A[:,-i]))),1))\n",
        "      grad_H[-i-1,:].assign(tf.tensordot(tf.reshape(G[-i-1,:], (1,-1)),self.V,1)+tf.tensordot(tf.reshape(grad_A[-i,:], (1,-1)),self.W,1))\n",
        "    grad_A[0,:].assign(tf.tensordot(tf.reshape(grad_H[0,:],(1,-1)),tf.linalg.diag(tf.ones(self.m)-tf.math.square(tf.math.tanh(A[:,0]))),1))\n",
        "\n",
        "    #dL/db\n",
        "    grads.b.assign(tf.reduce_sum(grad_A, axis=0))\n",
        "\n",
        "    #dL/dW\n",
        "    for i in range(self.seq_length):\n",
        "      grads.W.assign(grads.W+tf.tensordot(grad_A[i,:],H[:,i],0))\n",
        "\n",
        "    #dL/dU\n",
        "    for i in range(self.seq_length):\n",
        "      grads.U.assign(grads.U+tf.tensordot(grad_A[i,:],X[:,i],0))\n",
        "\n",
        "    return grads\n",
        "\n",
        "  def loss(self, X, Y, P):\n",
        "    pass\n",
        "\n",
        "  def train(self, eta, steps):\n",
        "    #TODO: replace with real data/batches\n",
        "    X = tf.Variable(tf.zeros_initializer()(shape = (80, 25)))\n",
        "    Y = tf.Variable(tf.zeros_initializer()(shape = (80, 25)))\n",
        "    P, H, A = self.forwardPass(X,Y)\n",
        "    grads = self.backwardPass(X, Y, P, H, A)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(25, 100, 80, 0.01)\n",
        "x = tf.Variable(tf.zeros_initializer()(shape = (80, 25)))\n",
        "rnn.train(1e-2,10)"
      ],
      "metadata": {
        "id": "6HN68JHo5Dlx"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Y = tf.Variable(np.array([[1,2],[3,4]]))\n",
        "P = tf.Variable(np.array([[1,1],[1,1]]))\n"
      ],
      "metadata": {
        "id": "5JMeUP6NYWl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=[1,2,3]\n",
        "tf.linalg.diag(a)"
      ],
      "metadata": {
        "id": "uV8ydtCtkZRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annamaartensson/dd2424project/blob/issue%2F18/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7fD8wIJNDciU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc91e28-dd6a-4f0a-e17a-b879fb5f494b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F39H_ZUFDciW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0cd2e3ce-ee89-4e01-edc6-070600f1e1f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sGcepYKOSArx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os\n",
        "import platform\n",
        "import re\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCi4Npp_DciX"
      },
      "source": [
        "Fetch and process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u2PJaZCT3vx0"
      },
      "outputs": [],
      "source": [
        "def fetch_data():\n",
        "  cache_dir = \"./tmp\"\n",
        "  dataset_file_name = \"pg31100.txt\"\n",
        "  dataset_file_origin = \"https://www.gutenberg.org/cache/epub/31100/pg31100.txt\"\n",
        "  dataset_file_path = tf.keras.utils.get_file(fname = dataset_file_name, origin = dataset_file_origin, cache_dir=pathlib.Path(cache_dir).absolute())\n",
        "  text = open(dataset_file_path, mode = \"r\").read()\n",
        "  persuasion = text[1437:468297]\n",
        "  northanger_abbey = text[468297:901707]\n",
        "  mansfield_park = text[901707:1784972]\n",
        "  emma = text[1784972:2668012]\n",
        "  lady_susan = text[2668012:2795312]\n",
        "  love_and_friendship = text[2795312:2980261]\n",
        "  pride_and_predjudice = text[2980261:3665048]\n",
        "  sense_and_sensibility = text[3682008:4355100]\n",
        "  full_text = text[1437:4355100]\n",
        "  books = [persuasion, northanger_abbey, mansfield_park, emma, lady_susan, love_and_friendship, pride_and_predjudice, sense_and_sensibility]\n",
        "  return books"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcGWPpCFDciY"
      },
      "source": [
        "Text to tensor encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4j2E-p4BOOEF"
      },
      "outputs": [],
      "source": [
        "class BasicEncoder:\n",
        "\n",
        "  def __init__(self, text):\n",
        "    self.vocabulary = sorted(set(text))\n",
        "    self.ind_to_token = list(self.vocabulary)\n",
        "    self.ind_to_token.insert(0, \"[UNK]\")\n",
        "    self.token_to_ind = {self.ind_to_token[i] : i for i in range(len(self.ind_to_token))}\n",
        "\n",
        "  def get_size(self):\n",
        "    return len(self.ind_to_token)\n",
        "\n",
        "  def text_to_inds(self, text):\n",
        "    inds = []\n",
        "    for c in text:\n",
        "      if c in self.token_to_ind:\n",
        "        inds.append(self.token_to_ind[c])\n",
        "      else:\n",
        "        inds.append(self.token_to_ind[\"[UNK]\"])\n",
        "    return inds\n",
        "\n",
        "class BytePairEncoder(BasicEncoder):\n",
        "\n",
        "  def __init__(self, text, target_size):\n",
        "    super().__init__(text)\n",
        "    self.__expand_vocabulary(text, target_size)\n",
        "\n",
        "  def __merge_pairs(self, tokens, pair, val):\n",
        "    merged_tokens = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "      if tokens[i] == pair[0] and i < len(tokens)-1 and tokens[i+1] == pair[1]:\n",
        "        merged_tokens.append(val)\n",
        "        i += 2\n",
        "      else:\n",
        "        merged_tokens.append(tokens[i])\n",
        "        i += 1\n",
        "    return merged_tokens\n",
        "\n",
        "  def __get_pair_counts(self, tokens):\n",
        "    counts = {}\n",
        "    for i in range(len(tokens)-1):\n",
        "      pair = tokens[i], tokens[i+1]\n",
        "      if pair not in counts:\n",
        "        counts[pair] = 1\n",
        "      else:\n",
        "        counts[pair] += 1\n",
        "    return counts\n",
        "\n",
        "  def __expand_vocabulary(self, text, target_size):\n",
        "    self.merges = {}\n",
        "    tokens = [self.token_to_ind[c] for c in text]\n",
        "    while self.get_size() < target_size:\n",
        "      counts = self.__get_pair_counts(tokens)\n",
        "      best_pair = max(counts, key = counts.get)\n",
        "      new_token = self.ind_to_token[best_pair[0]]+self.ind_to_token[best_pair[1]]\n",
        "      new_val = len(self.ind_to_token)\n",
        "      self.ind_to_token.append(new_token)\n",
        "      self.token_to_ind[new_token] = new_val\n",
        "      self.merges[best_pair] = new_val\n",
        "      tokens = self.__merge_pairs(tokens, best_pair, new_val)\n",
        "\n",
        "  def text_to_inds(self,text):\n",
        "    inds = super().text_to_inds(text)\n",
        "    found_merge = True\n",
        "    while found_merge:\n",
        "      merged_inds = []\n",
        "      found_merge = False\n",
        "      i = 0\n",
        "      while i < len(inds):\n",
        "        if i < len(inds)-1 and (inds[i], inds[i+1]) in self.merges:\n",
        "          merged_inds.append(self.merges[(inds[i], inds[i+1])])\n",
        "          found_merge = True\n",
        "          i += 2\n",
        "        else:\n",
        "          merged_inds.append(inds[i])\n",
        "          i += 1\n",
        "      inds = merged_inds\n",
        "    return inds\n",
        "\n",
        "class WordEncoder(BasicEncoder):\n",
        "\n",
        "  def __init__(self, text):\n",
        "    super().__init__(self.split_text(text))\n",
        "\n",
        "  def text_to_inds(self, text):\n",
        "    text = self.split_text(text)\n",
        "    inds = []\n",
        "    for c in text:\n",
        "      if c in self.token_to_ind:\n",
        "        inds.append(self.token_to_ind[c])\n",
        "      else:\n",
        "        inds.append(self.token_to_ind[\"[UNK]\"])\n",
        "    return inds\n",
        "\n",
        "  def split_text(self, text):\n",
        "    no_spec = re.split(\"(\\&|\\[|\\]|\\n|-| |\\_|!|\\?|\\*|\\.|,|\\(|\\)|;|:|[0-9]+|\\\"|\\')\", text)\n",
        "    return list(filter(lambda a: a != \"\", no_spec))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22XTx90-DciZ"
      },
      "source": [
        "Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GS-txsIIVe2c"
      },
      "outputs": [],
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, K, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.target_embedding = tf.keras.layers.Embedding(K, embedding_dim, name = \"target\")\n",
        "    self.context_embedding = tf.keras.layers.Embedding(K, embedding_dim)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    word_embedding = self.target_embedding(pair[0])\n",
        "    context_embedding = self.context_embedding(pair[1])\n",
        "    return tf.einsum(\"be,bce->bc\", word_embedding, context_embedding)\n",
        "\n",
        "def batch_data_w2v(text, seq_length, encoder, window_size, n_neg_samples, batch_size, buffer_size):\n",
        "  inds = encoder.text_to_inds(text)\n",
        "  sequences = [inds[i:i+seq_length] for i in range(int(len(inds)/seq_length-seq_length))]\n",
        "  targets, contexts, labels = [], [], []\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(encoder.get_size())\n",
        "  for seq in sequences:\n",
        "    pos_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(seq, vocabulary_size = encoder.get_size(), sampling_table = sampling_table, window_size = window_size, negative_samples = 0)\n",
        "    for target, context in pos_skip_grams:\n",
        "      true_context = tf.expand_dims(tf.constant([context], dtype = \"int64\"), 1)\n",
        "      neg_samples, _, _ = tf.random.log_uniform_candidate_sampler(true_classes = true_context, num_true = 1, num_sampled = n_neg_samples, unique = True, range_max = encoder.get_size())\n",
        "      context = tf.concat([tf.squeeze(true_context, 1), neg_samples], 0)\n",
        "      label = tf.constant([1] + [0]*n_neg_samples, dtype = \"int64\")\n",
        "      targets.append(target)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "  examples = tf.data.Dataset.from_tensor_slices(((np.array(targets), np.array(contexts)), np.array(labels)))\n",
        "  batches = examples.shuffle(buffer_size).batch(batch_size, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
        "  return batches\n",
        "\n",
        "def get_w2v_weights(text, seq_length, encoder, embedding_dim, window_size, n_neg_samples, batch_size, buffer_size):\n",
        "  training_data = batch_data_w2v(text, seq_length, encoder, window_size, n_neg_samples, batch_size, buffer_size)\n",
        "  word2vec = Word2Vec(encoder.get_size(), embedding_dim)\n",
        "  word2vec.compile(optimizer = \"adam\", loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True), metrics=[\"accuracy\"])\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs\")\n",
        "  word2vec.fit(training_data, epochs = 20, callbacks = [tensorboard_callback]) #tensorboard\n",
        "  weights = word2vec.get_layer(\"target\").get_weights()[0]\n",
        "  return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-VoYe2SDcia"
      },
      "source": [
        "Generate batches from text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9SvmYFn09g5D"
      },
      "outputs": [],
      "source": [
        "def batch_data(text, encoder, embedder, seq_length = 0, batch_size = 1, buffer_size = 0):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoder.text_to_inds(text))\n",
        "  if seq_length == 0:\n",
        "    seq_length = dataset.cardinality()-1\n",
        "  sequences = dataset.batch(seq_length+1, drop_remainder = True).map(lambda s : (s[:seq_length], s[1:]))\n",
        "  sequences = sequences.map(lambda x, y: (embedder(x), y))\n",
        "  if buffer_size > 0:\n",
        "    sequences = sequences.shuffle(buffer_size)\n",
        "  batches = sequences.batch(batch_size, drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6YDelUqDcib"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BW1AW2EEDcib"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "  def __init__(self, encoder, embedder):\n",
        "    self.encoder = encoder\n",
        "    self.embedder = embedder\n",
        "    self.WANB = True\n",
        "\n",
        "  @tf.function\n",
        "  def loss(self, X, Y, seq_length = 1):\n",
        "    states = self.initial_states\n",
        "    L = 0.0\n",
        "    for t in range(seq_length):\n",
        "      logits, states = self(X[t,:], states)\n",
        "      logits = tf.math.log(tf.nn.softmax(logits))\n",
        "      L -= logits[Y[t]]\n",
        "    return L\n",
        "\n",
        "  def fit(self, batches, val_batches, spelling_dictionary, epochs, learning_rate):\n",
        "    steps_per_epoch = batches.cardinality().numpy()\n",
        "    self.optimizer = tf.keras.optimizers.Adagrad(learning_rate = learning_rate, epsilon = 1e-8, clipvalue = 5)\n",
        "    smooth_loss = None\n",
        "    step = 0\n",
        "    for batch in batches.repeat(epochs):\n",
        "      X_batch, Y_batch = batch\n",
        "      grads_batch = []\n",
        "      n_batch = tf.shape(X_batch)[0].numpy()\n",
        "      seq_length = tf.shape(X_batch)[1].numpy()\n",
        "      for X, Y in zip(X_batch, Y_batch):\n",
        "        if smooth_loss == None:\n",
        "          smooth_loss = self.loss(X, Y, seq_length)\n",
        "        else:\n",
        "          smooth_loss = 0.999*smooth_loss + 0.001*self.loss(X, Y, seq_length)\n",
        "        with tf.GradientTape() as tape:\n",
        "          tape.watch(self.variables)\n",
        "          loss = self.loss(X, Y, seq_length)\n",
        "        grads = tape.gradient(loss, self.variables)\n",
        "        if grads_batch == []:\n",
        "          grads_batch = [g / n_batch for g in grads]\n",
        "        else:\n",
        "          for i in range(len(grads)):\n",
        "            grads_batch[i] = grads_batch[i] + grads[i]/n_batch\n",
        "      self.optimizer.apply_gradients(zip(grads_batch, self.variables))\n",
        "      if (step % steps_per_epoch == 0):\n",
        "        print(\"\\nEPOCH\", step // steps_per_epoch)\n",
        "        print(\"Smooth Loss:\", smooth_loss.numpy())\n",
        "        val_loss = 0\n",
        "        val_count = 0\n",
        "        for val_batch in val_batches:\n",
        "          X_val_batch, Y_val_batch = batch\n",
        "          seq_length_val = tf.shape(X_val_batch)[1].numpy()\n",
        "          for X_val, Y_val in zip(X_val_batch, Y_val_batch):\n",
        "            val_loss = val_loss + self.loss(X_val, Y_val, seq_length_val)\n",
        "            val_count = val_count + 1\n",
        "        print(\"Average validation loss:\", val_loss.numpy()/val_count)\n",
        "        print(\"Validation perplexity:\", tf.math.pow(val_loss/(seq_length_val*val_count), 2).numpy())\n",
        "        text = self.generate_text_temperature('.', 200)\n",
        "        cor_spell=correctly_spelled(text, spelling_dictionary)\n",
        "        print(\"Text generation correctly spelled:\", cor_spell)\n",
        "        print(text)\n",
        "        wandb.log({\"Smooth Loss\": smooth_loss.numpy(), \"Average validation loss\": val_loss.numpy()/val_count, \"Validation perplexity\": tf.math.pow(val_loss/(seq_length_val*val_count), 2).numpy(), \"Text generation correctly spelled\":cor_spell})\n",
        "      step = step + 1\n",
        "\n",
        "  def generate_text_temperature(self, start, length, T = 1.0):\n",
        "    text = []\n",
        "    states = self.initial_states\n",
        "    start = tf.squeeze(self.embedder(np.expand_dims(self.encoder.text_to_inds(start), axis = 0)))\n",
        "    unk_ind = self.encoder.token_to_ind[\"[UNK]\"]\n",
        "    sparse_unk_mask = tf.SparseTensor(values = [-float(\"inf\")], indices = [[unk_ind]], dense_shape=[self.encoder.get_size()])\n",
        "    for i in range(length):\n",
        "      H = states\n",
        "      logits, states = self(start, states)\n",
        "      logits = logits/T\n",
        "      logits = logits + tf.sparse.to_dense(sparse_unk_mask)\n",
        "      pred = tf.random.categorical([logits], num_samples = 1)\n",
        "      start = tf.squeeze(self.embedder(pred))\n",
        "      text.append(self.encoder.ind_to_token[tf.squeeze(pred).numpy()])\n",
        "    return \"\".join(text)\n",
        "\n",
        "  def generate_text_nucleus(self, start, length, theta = 1.0):\n",
        "    text = []\n",
        "    states = self.initial_states\n",
        "    start = tf.squeeze(self.embedder(np.expand_dims(self.encoder.text_to_inds(start), axis = 0)))\n",
        "    unk_ind = self.encoder.token_to_ind[\"[UNK]\"]\n",
        "    sparse_unk_mask = tf.SparseTensor(values = [-float(\"inf\")], indices = [[unk_ind]], dense_shape=[self.encoder.get_size()])\n",
        "    for i in range(length):\n",
        "      logits, states = self(start, states)\n",
        "      logits = logits + tf.sparse.to_dense(sparse_unk_mask)\n",
        "      probs = tf.nn.softmax(logits)\n",
        "      sorted_probs = tf.sort(probs, direction = \"DESCENDING\")\n",
        "      sorted_probs_sum = tf.math.cumsum(sorted_probs)\n",
        "      thresh_inds = tf.where(sorted_probs_sum <= theta)\n",
        "      if len(thresh_inds) > 0:\n",
        "        thresh_ind = thresh_inds[-1, 0].numpy()\n",
        "      else:\n",
        "        thresh_ind = 0\n",
        "      top_probs = tf.multiply(probs, tf.cast(probs >= sorted_probs[thresh_ind], \"float32\"))/sorted_probs_sum[thresh_ind]\n",
        "      pred = tf.random.categorical([tf.math.log(top_probs)], num_samples = 1)\n",
        "      start = tf.squeeze(self.embedder(pred))\n",
        "      text.append(self.encoder.ind_to_token[tf.squeeze(pred).numpy()])\n",
        "    return \"\".join(text)\n",
        "\n",
        "class RNN(Model):\n",
        "  def __init__(self, encoder, embedder, m, sig = 0.01):\n",
        "    super().__init__(encoder, embedder)\n",
        "    self.embedding_dim = embedder.output_dim\n",
        "    self.m = m\n",
        "    self.K = encoder.get_size()\n",
        "    self.b = tf.Variable(tf.zeros_initializer()(shape = (self.m)))\n",
        "    self.c = tf.Variable(tf.zeros_initializer()(shape = (self.K)))\n",
        "    self.U = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.m, self.embedding_dim)))\n",
        "    self.W = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.m, self.m)))\n",
        "    self.V = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.K, self.m)))\n",
        "    self.variables = [self.b, self.c, self.U, self.W, self.V]\n",
        "    self.initial_states = np.zeros(shape = (self.m), dtype = np.float32)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, X, states):\n",
        "    H = states\n",
        "    A = tf.linalg.matvec(self.W, H) + tf.linalg.matvec(self.U, X) + self.b\n",
        "    H = tf.math.tanh(A)\n",
        "    O = tf.linalg.matvec(self.V, H) + self.c\n",
        "    return O, H\n",
        "\n",
        "class LSTM(Model):\n",
        "  def __init__(self, encoder, embedder, m, sig = 0.01):\n",
        "    super().__init__(encoder, embedder)\n",
        "    self.embedding_dim = embedder.output_dim\n",
        "    self.m = m\n",
        "    self.K = encoder.get_size()\n",
        "    self.b = tf.Variable(tf.zeros_initializer()(shape = (4*self.m)))\n",
        "    self.c = tf.Variable(tf.zeros_initializer()(shape = (self.K)))\n",
        "    self.U = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.embedding_dim)))\n",
        "    self.W = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.m)))\n",
        "    self.V = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.K, self.m)))\n",
        "    self.variables = [self.b, self.c, self.U, self.W, self.V]\n",
        "    self.initial_states = np.zeros(shape = (self.m), dtype = np.float32)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, X, states):\n",
        "    H = states\n",
        "    A = tf.linalg.matvec(self.W, H) + tf.linalg.matvec(self.U, X) + self.b\n",
        "    f = tf.math.sigmoid(A[:self.m])\n",
        "    i = tf.math.sigmoid(A[self.m:2*self.m])\n",
        "    o = tf.math.sigmoid(A[2*self.m:3*self.m])\n",
        "    H = tf.math.tanh(A[3*self.m:])\n",
        "    O = tf.linalg.matvec(self.V, H) + self.c\n",
        "    return O, H\n",
        "\n",
        "class LSTM2(Model):\n",
        "  def __init__(self, encoder, embedder, m, sig = 0.01):\n",
        "    super().__init__(encoder, embedder)\n",
        "    self.embedding_dim = embedder.output_dim\n",
        "    self.m = m\n",
        "    self.K = encoder.get_size()\n",
        "    self.b1 = tf.Variable(tf.zeros_initializer()(shape = (4*self.m)))\n",
        "    self.b2 = tf.Variable(tf.zeros_initializer()(shape = (4*self.m)))\n",
        "    self.c = tf.Variable(tf.zeros_initializer()(shape = (self.K)))\n",
        "    self.U1 = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.embedding_dim)))\n",
        "    self.W1 = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.m)))\n",
        "    self.U2 = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.m)))\n",
        "    self.W2 = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (4*self.m, self.m)))\n",
        "    self.V = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.K, self.m)))\n",
        "    self.variables = [self.b1, self.b2, self.c, self.U1, self.U2, self.W1, self.W2, self.V]\n",
        "    self.initial_states = [np.zeros(shape = (self.m), dtype = np.float32), np.zeros(shape = (self.m), dtype = np.float32)]\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, X, states):\n",
        "    H1, H2 = states\n",
        "    A1 = tf.linalg.matvec(self.W1, H1) + tf.linalg.matvec(self.U1, X) + self.b1\n",
        "    f1 = tf.math.sigmoid(A1[:self.m])\n",
        "    i1 = tf.math.sigmoid(A1[self.m:2*self.m])\n",
        "    o1 = tf.math.sigmoid(A1[2*self.m:3*self.m])\n",
        "    H1 = tf.math.tanh(A1[3*self.m:])\n",
        "    A2 = tf.linalg.matvec(self.W2, H2) + tf.linalg.matvec(self.U2, H1) + self.b2\n",
        "    f2 = tf.math.sigmoid(A2[:self.m])\n",
        "    i2 = tf.math.sigmoid(A2[self.m:2*self.m])\n",
        "    o2 = tf.math.sigmoid(A2[2*self.m:3*self.m])\n",
        "    H2 = tf.math.tanh(A2[3*self.m:])\n",
        "    O = tf.linalg.matvec(self.V, H2) + self.c\n",
        "    return O, [H1, H2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iSGXTUDcic"
      },
      "source": [
        "Dictionary of known words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vm-tXKuC7MTN"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  lower = text.lower()\n",
        "  no_spec = re.sub(\"\\&|\\[|\\]|\\_|!|\\?|\\*|\\.|,|\\(|\\)|;|:|[0-9]+|\\\"|\\'\",\"\", lower)\n",
        "  no_enter = re.sub(\"\\n|-\",\" \", no_spec)\n",
        "  return no_enter.split()\n",
        "\n",
        "def get_dictionary(text):\n",
        "  dictionary = {w for w in clean_text(text)}\n",
        "  return dictionary\n",
        "\n",
        "def correctly_spelled(text, dictionary):\n",
        "  count = 0\n",
        "  words = clean_text(text)\n",
        "  for w in clean_text(text):\n",
        "    if w in dictionary:\n",
        "      count += 1\n",
        "  return count/len(words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config=None):\n",
        "  with wandb.init(config=config, project = \"ProjectDD2424\"):\n",
        "      config = wandb.config\n",
        "      print(config.seq_length)"
      ],
      "metadata": {
        "id": "5l3VlhoxphOg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full batching and training loop"
      ],
      "metadata": {
        "id": "DtZOTTGPvnw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SlS6ITj4PQeO"
      },
      "outputs": [],
      "source": [
        "def batch_and_train(config=None):\n",
        "    with wandb.init(config=config):\n",
        "      config = wandb.config\n",
        "      # finding encoder\n",
        "      if (config.encoder=='basic'):\n",
        "        encoder, embedder = basic_encoder, basic_embedder\n",
        "      elif(config.encoder=='byte_pair'):\n",
        "        encoder, embedder = byte_pair_encoder, byte_pair_embedder\n",
        "      else:\n",
        "        encoder, embedder = word_encoder, word_embedder\n",
        "\n",
        "      training_batches = batch_data(training_text, encoder, embedder, math.floor(config.seq_length), config.batch_size, config.buffer_size)\n",
        "      validation_batches = batch_data(validation_text, encoder, embedder)\n",
        "\n",
        "      # finding model\n",
        "      if (config.model==\"LSTM\"):\n",
        "        model = LSTM(encoder, embedder, config.m)\n",
        "      elif (config.model==\"LSTM2\"):\n",
        "        model = LSTM(encoder, embedder, config.m)\n",
        "      else:\n",
        "        model = RNN(encoder, embedder, config.m)\n",
        "\n",
        "      epochs=math.floor(112/int(training_batches.cardinality())) # s.t. update step stays constant: 112\n",
        "      model.fit(training_batches, validation_batches, spelling_dictionary, epochs, config.learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_parameter_search(encoder, model, spelling_dictionary, training_text, validation_text):\n",
        "  # hyper-parameter tuning\n",
        "    sweep_config = {'method': 'random'}\n",
        "    metric = {'name': 'Average validation loss','goal': 'minimize'}\n",
        "    sweep_config['metric'] = metric\n",
        "    parameters_dict = {'buffer_size': {'values': [10000]},'encoder': {'values': [encoder]},'model': {'values': [model]}}\n",
        "    sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "    parameters_dict.update({\n",
        "    'learning_rate': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.0001,\n",
        "        'max': 0.1\n",
        "      },\n",
        "    'm': {\n",
        "        'distribution': 'q_log_uniform_values',\n",
        "        'q': 8,\n",
        "        'min': 64,\n",
        "        'max': 512,\n",
        "      },\n",
        "      'batch_size': { # with evenly-distributed logarithms between 16 and 256\n",
        "        'distribution': 'q_log_uniform_values',\n",
        "        'q': 8,\n",
        "        'min': 16,\n",
        "        'max': 256,\n",
        "      },\n",
        "      'seq_length': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 25,\n",
        "        'max': 175,\n",
        "      },\n",
        "    })\n",
        "\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"ProjectDD2424\") # ProjectDD2424 is the wandb project were this ends up\n",
        "    wandb.agent(sweep_id, batch_and_train, count=8) # count sets the number of experiments conducted\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "sP95w_HTl0_s"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments"
      ],
      "metadata": {
        "id": "6T7843Liwwgi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "haY4WnUWDcid",
        "outputId": "7cb7a8c9-ed44-4726-9d6a-cf8788fd891f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cfdf11a1ea34>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mw2v_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mw2v_embedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mw2v_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_w2v_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neg_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mword_embedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw2v_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-64e6b915cf74>\u001b[0m in \u001b[0;36mget_w2v_weights\u001b[0;34m(text, seq_length, encoder, embedding_dim, window_size, n_neg_samples, batch_size, buffer_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_w2v_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data_w2v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-64e6b915cf74>\u001b[0m in \u001b[0;36mbatch_data_w2v\u001b[0;34m(text, seq_length, encoder, window_size, n_neg_samples, batch_size, buffer_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mneg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_uniform_candidate_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_neg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_neg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    294\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    295\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "books = fetch_data()\n",
        "\n",
        "training_text = books[0] #+ books[1] + books[2] + books[3] + books[4] + books[5] - two books when parameter search :D\n",
        "validation_text = books[6]\n",
        "test_text = books[7]\n",
        "\n",
        "basic_encoder = BasicEncoder(training_text)\n",
        "byte_pair_encoder = BytePairEncoder(training_text, 200)\n",
        "word_encoder = WordEncoder(training_text)\n",
        "\n",
        "basic_embedder = tf.keras.layers.Embedding(basic_encoder.get_size(), basic_encoder.get_size(), embeddings_initializer = \"identity\")\n",
        "byte_pair_embedder = tf.keras.layers.Embedding(byte_pair_encoder.get_size(), byte_pair_encoder.get_size(), embeddings_initializer = \"identity\")\n",
        "w2v_seq_length = 10\n",
        "w2v_embedding_dim = 128\n",
        "w2v_weights = get_w2v_weights(training_text, w2v_seq_length, word_encoder, w2v_embedding_dim, window_size = 2, n_neg_samples = 4, batch_size = 1024, buffer_size = 10000)\n",
        "word_embedder = tf.keras.layers.Embedding(word_encoder.get_size(), w2v_embedding_dim, weights = [w2v_weights], trainable = False)\n",
        "\n",
        "spelling_dictionary = get_dictionary(training_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = \"basic\" # basic, byte_pair or word\n",
        "model = \"LSTM\" # LSTM, LSTM2 or RNN\n",
        "random_parameter_search(encoder, model, spelling_dictionary, training_text, validation_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857,
          "referenced_widgets": [
            "1b63eef0ac864cd385893167c2dc7ac4",
            "626820cabbc8499a88abd47826d5033a",
            "f1056bd43e39477fbf7c372df4222a55",
            "0e92b80cb0534d9f882c8bafb5a0cfcc",
            "007171ab87584805b1682809d36c3326",
            "403710f9b01240cc87ea413d26cf16f0",
            "0ece2b14b8904c4f83f0ca90268f7c4a",
            "006aa6c8386840beb1d22b5e057ab866"
          ]
        },
        "id": "T2eSVC9DqBPk",
        "outputId": "193b8f4b-e874-4706-f75f-daebb1ea013c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: on9dcmau\n",
            "Sweep URL: https://wandb.ai/eirasorg/ProjectDD2424/sweeps/on9dcmau\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3ajr1wfe with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 176\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbuffer_size: 10000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder: basic\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09548142310931304\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_length: 153.47761764139236\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240520_162153-3ajr1wfe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/3ajr1wfe' target=\"_blank\">apricot-sweep-1</a></strong> to <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/eirasorg/ProjectDD2424/sweeps/on9dcmau' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/sweeps/on9dcmau</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/eirasorg/ProjectDD2424/sweeps/on9dcmau' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/sweeps/on9dcmau</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/3ajr1wfe' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/runs/3ajr1wfe</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 0\n",
            "Smooth Loss: 662.6234\n",
            "Average validation loss: 643.0992986505681\n",
            "Validation perplexity: 17.667421\n",
            "Text generation correctly spelled: 0.0\n",
            "F&4'8f:In8C0GoSwIr(n3QY2n.znbSl0\",QfuqvGU\")L6C&R'MTF ueH7H5oOBmay\n",
            "aMhl8Wg0pTd\n",
            "vGPu8Lm,o0MIMU\"uhYpsxJmiBlEu,(jAJKm\n",
            ",aH0vSC5zqP.I(Hzy9pnARZ1D(!LlLx52a0Vl2DU;eUhIu-zPHJcMnlDIt7pIo.,:cTaCp&EajIjlYzRL?gTq \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b63eef0ac864cd385893167c2dc7ac4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average validation loss</td><td>▁</td></tr><tr><td>Smooth Loss</td><td>▁</td></tr><tr><td>Text generation correctly spelled</td><td>▁</td></tr><tr><td>Validation perplexity</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average validation loss</td><td>643.0993</td></tr><tr><td>Smooth Loss</td><td>662.62341</td></tr><tr><td>Text generation correctly spelled</td><td>0.0</td></tr><tr><td>Validation perplexity</td><td>17.66742</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">apricot-sweep-1</strong> at: <a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/3ajr1wfe' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/runs/3ajr1wfe</a><br/> View project at: <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240520_162153-3ajr1wfe/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b63eef0ac864cd385893167c2dc7ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_626820cabbc8499a88abd47826d5033a",
              "IPY_MODEL_f1056bd43e39477fbf7c372df4222a55"
            ],
            "layout": "IPY_MODEL_0e92b80cb0534d9f882c8bafb5a0cfcc"
          }
        },
        "626820cabbc8499a88abd47826d5033a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007171ab87584805b1682809d36c3326",
            "placeholder": "​",
            "style": "IPY_MODEL_403710f9b01240cc87ea413d26cf16f0",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "f1056bd43e39477fbf7c372df4222a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ece2b14b8904c4f83f0ca90268f7c4a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_006aa6c8386840beb1d22b5e057ab866",
            "value": 1
          }
        },
        "0e92b80cb0534d9f882c8bafb5a0cfcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007171ab87584805b1682809d36c3326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403710f9b01240cc87ea413d26cf16f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ece2b14b8904c4f83f0ca90268f7c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006aa6c8386840beb1d22b5e057ab866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
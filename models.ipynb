{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/annamaartensson/dd2424project/blob/issue%2F15c/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGcepYKOSArx",
    "outputId": "4a692041-8904-4e35-f64e-79ffe003c7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9\n",
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "\n",
    "print(platform.python_version())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP5FtJXOO9Y9",
    "outputId": "c3ed9a04-4ae8-4eb1-9f78-55a251f0ce94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -qq -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "GpdpiyOvO47k",
    "outputId": "2b35539e-604f-4eaa-ac1e-d54327a96346"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u2PJaZCT3vx0"
   },
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "  cache_dir = './tmp'\n",
    "  dataset_file_name = 'pg31100.txt'\n",
    "  dataset_file_origin = 'https://www.gutenberg.org/cache/epub/31100/pg31100.txt'\n",
    "  dataset_file_path = tf.keras.utils.get_file(fname = dataset_file_name, origin = dataset_file_origin, cache_dir=pathlib.Path(cache_dir).absolute())\n",
    "  text = open(dataset_file_path, mode='r').read()\n",
    "  persuasion = text[1437:468297]\n",
    "  northanger_abbey = text[468297:901707]\n",
    "  mansfield_park = text[901707:1784972]\n",
    "  emma = text[1784972:2668012]\n",
    "  lady_susan = text[2668012:2795312]\n",
    "  love_and_friendship = text[2795312:2980261]\n",
    "  pride_and_predjudice = text[2980261:3665048]\n",
    "  sense_and_sensibility = text[3682008:4355100]\n",
    "  full_text = text[1437:4355100]\n",
    "  books = [persuasion, northanger_abbey, mansfield_park, emma, lady_susan, love_and_friendship, pride_and_predjudice, sense_and_sensibility]\n",
    "  return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B1yAnpun7zaz"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  lower = text.lower()\n",
    "  no_spec = re.sub(\"\\&|\\[|\\]|\\_|!|\\?|\\*|\\.|,|\\(|\\)|;|:|[0-9]+|\\\"|\\'\",\"\", lower)\n",
    "  no_enter = re.sub(\"\\n|-\",\" \", no_spec)\n",
    "  return no_enter.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v9cEaIck7fCh"
   },
   "outputs": [],
   "source": [
    "def get_dictionary(text):\n",
    "  dictionary = {w for w in clean_text(text)}\n",
    "  return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vm-tXKuC7MTN"
   },
   "outputs": [],
   "source": [
    "def correctly_spelled(text, dictionary):\n",
    "  count = 0\n",
    "  words = clean_text(text)\n",
    "  for w in clean_text(text):\n",
    "    if w in dictionary:\n",
    "      count += 1\n",
    "  return count/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4j2E-p4BOOEF"
   },
   "outputs": [],
   "source": [
    "class BasicEncoder:\n",
    "\n",
    "  def __init__(self, text):\n",
    "    self.vocabulary = sorted(set(text))\n",
    "    self.ind_to_token = list(self.vocabulary)\n",
    "    self.ind_to_token.insert(0, '[UNK]')\n",
    "    self.token_to_ind = {self.ind_to_token[i] : i for i in range(len(self.ind_to_token))}\n",
    "\n",
    "  def get_size(self):\n",
    "    return len(self.ind_to_token)\n",
    "\n",
    "  def text_to_inds(self, text):\n",
    "    inds = []\n",
    "    for c in text:\n",
    "      if c in self.token_to_ind:\n",
    "        inds.append(self.token_to_ind[c])\n",
    "      else:\n",
    "        inds.append(self.token_to_ind['[UNK]'])\n",
    "    return inds\n",
    "\n",
    "class BytePairEncoder(BasicEncoder):\n",
    "\n",
    "  def __init__(self, text, target_size):\n",
    "    super().__init__(text)\n",
    "    self.__expand_vocabulary(text, target_size)\n",
    "\n",
    "  def __merge_pairs(self, tokens, pair, val):\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "      if tokens[i] == pair[0] and i < len(tokens)-1 and tokens[i+1] == pair[1]:\n",
    "        merged_tokens.append(val)\n",
    "        i += 2\n",
    "      else:\n",
    "        merged_tokens.append(tokens[i])\n",
    "        i += 1\n",
    "    return merged_tokens\n",
    "\n",
    "  def __get_pair_counts(self, tokens):\n",
    "    counts = {}\n",
    "    for i in range(len(tokens)-1):\n",
    "      pair = tokens[i], tokens[i+1]\n",
    "      if pair not in counts:\n",
    "        counts[pair] = 1\n",
    "      else:\n",
    "        counts[pair] += 1\n",
    "    return counts\n",
    "\n",
    "  def __expand_vocabulary(self, text, target_size):\n",
    "    self.merges = {}\n",
    "    tokens = [self.token_to_ind[c] for c in text]\n",
    "    while self.get_size() < target_size:\n",
    "      counts = self.__get_pair_counts(tokens)\n",
    "      best_pair = max(counts, key = counts.get)\n",
    "      new_token = self.ind_to_token[best_pair[0]]+self.ind_to_token[best_pair[1]]\n",
    "      new_val = len(self.ind_to_token)\n",
    "      self.ind_to_token.append(new_token)\n",
    "      self.token_to_ind[new_token] = new_val\n",
    "      self.merges[best_pair] = new_val\n",
    "      tokens = self.__merge_pairs(tokens, best_pair, new_val)\n",
    "\n",
    "  def text_to_inds(self,text):\n",
    "    inds = super.text_to_inds(text)\n",
    "    found_merge = True\n",
    "    while found_merge:\n",
    "      merged_inds = []\n",
    "      found_merge = False\n",
    "      i = 0\n",
    "      while i < len(inds):\n",
    "        if i < len(inds)-1 and (inds[i], inds[i+1]) in self.merges:\n",
    "          merged_inds.append(self.merges[(inds[i], inds[i+1])])\n",
    "          found_merge = True\n",
    "          i += 2\n",
    "        else:\n",
    "          merged_inds.append(inds[i])\n",
    "          i += 1\n",
    "      inds = merged_inds\n",
    "    return inds\n",
    "\n",
    "class WordEncoder(BasicEncoder):\n",
    "\n",
    "  def __init__(self, text):\n",
    "    super().__init__(self.split_text(text))\n",
    "\n",
    "  def text_to_inds(self, text):\n",
    "    text = self.split_text(text)\n",
    "    inds = []\n",
    "    for c in text:\n",
    "      if c in self.token_to_ind:\n",
    "        inds.append(self.token_to_ind[c])\n",
    "      else:\n",
    "        inds.append(self.token_to_ind['[UNK]'])\n",
    "    return inds\n",
    "    #return super.text_to_inds(self.split_text(text))\n",
    "\n",
    "  def split_text(self, text):\n",
    "    no_spec = re.split(\"(\\&|\\[|\\]|\\n|-| |\\_|!|\\?|\\*|\\.|,|\\(|\\)|;|:|[0-9]+|\\\"|\\')\", text)\n",
    "    return list(filter(lambda a: a != '', no_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zo3h0-qtTAM_"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, K, embedding_dim):\n",
    "    super().__init__()\n",
    "    self.target_embedding = tf.keras.layers.Embedding(K, embedding_dim, name=\"target\")\n",
    "    self.context_embedding = tf.keras.layers.Embedding(K, embedding_dim)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    word_embedding = self.target_embedding(pair[0])\n",
    "    context_embedding = self.context_embedding(pair[1])\n",
    "    return tf.einsum('be,bce->bc', word_embedding, context_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GS-txsIIVe2c"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3034241026.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    sequences = [ids[i:i+seq_length for i in range(int(len(inds)/seq_length-seq_length))]]\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def batch_data_w2v(text, seq_length, encoder, window_size, n_neg_samples, batch_size, buffer_size):\n",
    "  inds = encoder.text_to_inds(text)\n",
    "  sequences = [ids[i:i+seq_length for i in range(int(len(inds)/seq_length-seq_length))]]\n",
    "  targets, contexts, labels = [], [], []\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(encoder.get_size())\n",
    "  for seq in sequences:\n",
    "    pos_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(seq, vocabulary_size = encoder.get_size(), sampling_table = sampling_table, window_size = window_size, negative_samples = 0)\n",
    "    for target, context in pos_skip_grams:\n",
    "      true_context = tf.expand_dims(tf.constant([context_word], dtype = \"int64\"), 1)\n",
    "      neg_samples, _ = tf.random.log_uniform_candidate_sampler(true_classes = true_context, num_true = 1, num_sampled = n_neg_samples, unique = True, range_max = encoder.get_size())\n",
    "      context = tf.concat([tf.squeeze(true_context, 1), neg_samples], 0)\n",
    "      label = tf.constant([1] + [0]*n_neg_samples, dtype = \"int64\")\n",
    "      targets.append(target)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "  examples = tf.data.Dataset.from_tensor_slices(((np.array(targets), np.array(contexts)), np.array(labels)))\n",
    "  batches = examples.shuffle(buffer_size).batch(batch_size, drop_remainder = True).prefetch(tf.data.AUTOTUNE)\n",
    "  return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LwnQPKNCS0q3"
   },
   "outputs": [],
   "source": [
    "def get_w2v_weights(text, seq_length, encoder, embedding_dim, window_size, n_neg_samples, batch_size, buffer_size):\n",
    "  training_data = get_w2v_training_examples(text, seq_length, encoder, window_size, n_neg_samples, batch_size, buffer_size)\n",
    "  word2vec = Word2Vec(encoder.get_size(), embedding_dim)\n",
    "  word2vec.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs\")\n",
    "  word2vec.fit(training_data, epochs = 20, callbacks = [tensorboard_callback]) #tensorboard\n",
    "  weights = word2vec.get_layer('w2v').get_weights()[0]\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9SvmYFn09g5D"
   },
   "outputs": [],
   "source": [
    "def batch_data(text, seq_length, encoder, embedder, batch_size = 1, buffer_size = 0):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(encoder.text_to_inds(text))\n",
    "  sequences = dataset.batch(seq_length+1, drop_remainder = True).map(lambda s : (s[:seq_length], s[1:]))\n",
    "  sequences = sequences.map(lambda x, y: (embedder(x), y))\n",
    "  if buffer_size > 0:\n",
    "    sequences = sequences.shuffle(buffer_size)\n",
    "  batches = sequences.batch(batch_size, drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "  def __init__(self, m, K, embedding_dim = None, sig = 0.1):\n",
    "    if embedding_dim == None:\n",
    "      self.embedding_dim = K\n",
    "    else:\n",
    "      self.embedding_dim = embedding_dim\n",
    "    self.m = m\n",
    "    self.K = K\n",
    "    self.b = tf.Variable(tf.zeros_initializer()(shape = (self.m)))\n",
    "    self.c = tf.Variable(tf.zeros_initializer()(shape = (self.K)))\n",
    "    self.U = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.m, self.embedding_dim)))\n",
    "    self.W = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.m, self.m)))\n",
    "    self.V = tf.Variable(tf.random_normal_initializer(mean = 0.0, stddev = sig)(shape = (self.K, self.m)))\n",
    "    self.variables = [self.b, self.c, self.U, self.W, self.V]\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, X, states = None):\n",
    "    seq_length = 25\n",
    "    if states == None:\n",
    "      states = np.zeros(shape = (self.m), dtype = np.float32)\n",
    "      Ps = [None]*seq_length\n",
    "      H = states\n",
    "      for t in range(seq_length):\n",
    "        A = tf.linalg.matvec(self.W, H) + tf.linalg.matvec(self.U, X[t,:]) + self.b\n",
    "        H = tf.math.tanh(A)\n",
    "        O = tf.linalg.matvec(self.V, H) + self.c\n",
    "        Ps[t] = tf.nn.softmax(O)\n",
    "      P = tf.stack([Ps[t] for t in range(seq_length)], 1)\n",
    "    return P, H\n",
    "\n",
    "  @tf.function\n",
    "  def loss(self, X, Y):\n",
    "    seq_length = 25\n",
    "    P, H = self(X)\n",
    "    L = 0\n",
    "    for t in range(seq_length):\n",
    "      L -= tf.math.log(P[Y[t],t])\n",
    "    return L\n",
    "\n",
    "  def backwardPass(self, X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(self.variables)\n",
    "      loss = self.loss(X, Y)\n",
    "    return tape.gradient(loss, self.variables)\n",
    "\n",
    "  def fit(self, batches, epochs, optimizer):\n",
    "    n_batch = 4\n",
    "    self.optimizer = optimizer\n",
    "    smooth_loss = None\n",
    "    step = 1\n",
    "    for batch in batches.repeat(epochs):\n",
    "      X_batch, Y_batch = batch\n",
    "      grads_batch = []\n",
    "      for X, Y in zip(X_batch, Y_batch):\n",
    "        if smooth_loss == None:\n",
    "          smooth_loss = self.loss(X, Y)\n",
    "        else:\n",
    "          smooth_loss = 0.999*smooth_loss + 0.001*self.loss(X, Y)\n",
    "        grads = self.backwardPass(X, Y)\n",
    "        if grads_batch == []:\n",
    "          grads_batch = [g / n_batch for g in grads]\n",
    "        else:\n",
    "          for i in range(len(grads)):\n",
    "            grads_batch[i] = grads_batch[i] + grads[i]/n_batch\n",
    "      self.optimizer.apply_gradients(zip(grads_batch, self.variables))\n",
    "      if (step % 1000 == 0):\n",
    "          print(\"Step:\", step, \"Loss:\", smooth_loss.numpy())\n",
    "      step = step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = fetch_data()\n",
    "\n",
    "training_text = books[0] #+ books[1] + books[2] + books[3] + books[4] + books[5]\n",
    "validation_text = books[6]\n",
    "test_text = books[7]\n",
    "\n",
    "encoder = BasicEncoder(training_text)\n",
    "embedder = tf.keras.layers.Embedding(encoder.get_size(), encoder.get_size(), embeddings_initializer = 'identity')\n",
    "\n",
    "training_batches = batch_data(training_text, 25, encoder, embedder, 4, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000 Loss: 78.81766\n",
      "Step: 2000 Loss: 76.4789\n",
      "Step: 3000 Loss: 75.31823\n",
      "Step: 4000 Loss: 74.10769\n",
      "Step: 5000 Loss: 73.08197\n",
      "Step: 6000 Loss: 72.312904\n",
      "Step: 7000 Loss: 71.65955\n",
      "Step: 8000 Loss: 71.20664\n",
      "Step: 9000 Loss: 70.35038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RNN(\u001b[38;5;241m128\u001b[39m, encoder\u001b[38;5;241m.\u001b[39mget_size())\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdagrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 58\u001b[0m, in \u001b[0;36mRNN.fit\u001b[0;34m(self, batches, epochs, optimizer)\u001b[0m\n\u001b[1;32m     56\u001b[0m   smooth_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(X, Y)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m   smooth_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.999\u001b[39m\u001b[38;5;241m*\u001b[39msmooth_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackwardPass(X, Y)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grads_batch \u001b[38;5;241m==\u001b[39m []:\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RNN(128, encoder.get_size())\n",
    "model.fit(training_batches, 4, tf.keras.optimizers.Adagrad(learning_rate = 0.001, epsilon = 1e-8, clipvalue = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBFPijVHUg_U"
   },
   "outputs": [],
   "source": [
    "class RNN(tf.keras.Model):\n",
    "  def __init__(self, K, m):\n",
    "    super().__init__(self)\n",
    "    self.rnn = tf.keras.layers.SimpleRNN(m, return_sequences = True, return_state = True)\n",
    "    self.dense = tf.keras.layers.Dense(K)\n",
    "\n",
    "  def call(self, inputs, states = None, return_state = False, training = False):\n",
    "    x = inputs\n",
    "    if states is None:\n",
    "      states = self.rnn.get_initial_state(x)\n",
    "    x, states = self.rnn(x, initial_state = states, training = training)\n",
    "    x = self.dense(x, training = training)\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "class LSTM(tf.keras.Model):\n",
    "  def __init__(self, K, m):\n",
    "    super().__init__(self)\n",
    "    self.lstm = tf.keras.layers.LSTM(m, return_sequences = True, return_state = True)\n",
    "    self.dense = tf.keras.layers.Dense(K)\n",
    "\n",
    "  def call(self, inputs, states = None, return_state = False, training = False):\n",
    "    x = inputs\n",
    "    if states is None:\n",
    "      states = self.lstm.get_initial_state(x)\n",
    "    x, *states = self.lstm(x, initial_state = states, training = training)\n",
    "    x = self.dense(x, training = training)\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "class LSTM2(tf.keras.Model):\n",
    "  def __init__(self, K, m):\n",
    "    super().__init__(self)\n",
    "    self.lstm1 = tf.keras.layers.LSTM(m, return_sequences = True, return_state = True)\n",
    "    self.lstm2 = tf.keras.layers.LSTM(m, return_sequences = True, return_state = True)\n",
    "    self.dense = tf.keras.layers.Dense(K)\n",
    "\n",
    "  def call(self, inputs, states = None, return_state = False, training = False):\n",
    "    x = inputs\n",
    "    if states is None:\n",
    "      states_1 = self.lstm1.get_initial_state(x)\n",
    "      states_2 = states_1\n",
    "    else:\n",
    "      states_1 = states[0]\n",
    "      states_2 = states[1]\n",
    "    x, *states_1 = self.lstm1(x, initial_state = states_1, training = training)\n",
    "    x, *states_2 = self.lstm2(x, initial_state = states_2, training = training)\n",
    "    x = self.dense(x, training = training)\n",
    "    if return_state:\n",
    "      return x, [states_1, states_2]\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OeRVBRY1-zzz"
   },
   "outputs": [],
   "source": [
    "def generate_text_temperature(start, length, model, encoder, embedder, T = 1.0):\n",
    "  text = []\n",
    "  states = None\n",
    "  start = embedder(np.expand_dims(encoder.text_to_inds(start), axis = 0))\n",
    "  for i in range(length):\n",
    "    logits, states = model(X = start, states = states)\n",
    "    logits = logits[:, -1, :]/T\n",
    "    pred = tf.random.categorical(logits, num_samples = 1)\n",
    "    start = embedder(pred)\n",
    "    text.append(encoder.ind_to_token[tf.squeeze(pred).numpy()])\n",
    "  return \"\".join(text)\n",
    "\n",
    "def generate_text_nucleus(start, length, model, encoder, embedder, theta = 1.0):\n",
    "  text = []\n",
    "  states = None\n",
    "  start = embedder(np.expand_dims(encoder.text_to_inds(start), axis = 0))\n",
    "  for i in range(length):\n",
    "    logits, states = model(X = start, states = states)\n",
    "    logits = logits[:, -1, :]\n",
    "    logits = tf.squeeze(logits, axis = 0)\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    sorted_probs = tf.sort(probs, direction = 'DESCENDING')\n",
    "    sorted_probs_sum = tf.math.cumsum(sorted_probs)\n",
    "    thresh_inds = tf.where(sorted_probs_sum <= theta)\n",
    "    if len(thresh_inds) > 0:\n",
    "      thresh_ind = thresh_inds[-1, 0].numpy()\n",
    "    else:\n",
    "      thresh_ind = 0\n",
    "    top_probs = tf.multiply(probs, tf.cast(probs >= sorted_probs[thresh_ind], 'float32'))/sorted_probs_sum[thresh_ind]\n",
    "    pred = tf.random.categorical([tf.math.log(top_probs)], num_samples = 1)\n",
    "    start = embedder(pred)\n",
    "    text.append(encoder.ind_to_token[tf.squeeze(pred).numpy()])\n",
    "  return \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIpJyuUo3wrb",
    "outputId": "d54c8b4f-96e4-4696-fb19-b562553b5f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "138/138 [==============================] - 6s 39ms/step - loss: 1.2334 - accuracy: 0.7607\n",
      "Epoch 2/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.5379 - accuracy: 0.8814\n",
      "Epoch 3/20\n",
      "138/138 [==============================] - 5s 39ms/step - loss: 0.3759 - accuracy: 0.9008\n",
      "Epoch 4/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.3272 - accuracy: 0.9073\n",
      "Epoch 5/20\n",
      "138/138 [==============================] - 6s 41ms/step - loss: 0.3022 - accuracy: 0.9116\n",
      "Epoch 6/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.2836 - accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "138/138 [==============================] - 5s 36ms/step - loss: 0.2673 - accuracy: 0.9205\n",
      "Epoch 8/20\n",
      "138/138 [==============================] - 3s 20ms/step - loss: 0.2521 - accuracy: 0.9258\n",
      "Epoch 9/20\n",
      "138/138 [==============================] - 3s 20ms/step - loss: 0.2379 - accuracy: 0.9310\n",
      "Epoch 10/20\n",
      "138/138 [==============================] - 4s 30ms/step - loss: 0.2246 - accuracy: 0.9361\n",
      "Epoch 11/20\n",
      "138/138 [==============================] - 4s 32ms/step - loss: 0.2123 - accuracy: 0.9408\n",
      "Epoch 12/20\n",
      "138/138 [==============================] - 3s 22ms/step - loss: 0.2010 - accuracy: 0.9450\n",
      "Epoch 13/20\n",
      "138/138 [==============================] - 4s 28ms/step - loss: 0.1907 - accuracy: 0.9488\n",
      "Epoch 14/20\n",
      "138/138 [==============================] - 4s 28ms/step - loss: 0.1813 - accuracy: 0.9526\n",
      "Epoch 15/20\n",
      "138/138 [==============================] - 4s 26ms/step - loss: 0.1729 - accuracy: 0.9563\n",
      "Epoch 16/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.1653 - accuracy: 0.9594\n",
      "Epoch 17/20\n",
      "138/138 [==============================] - 3s 24ms/step - loss: 0.1586 - accuracy: 0.9622\n",
      "Epoch 18/20\n",
      "138/138 [==============================] - 3s 25ms/step - loss: 0.1526 - accuracy: 0.9645\n",
      "Epoch 19/20\n",
      "138/138 [==============================] - 4s 29ms/step - loss: 0.1473 - accuracy: 0.9667\n",
      "Epoch 20/20\n",
      "138/138 [==============================] - 4s 30ms/step - loss: 0.1426 - accuracy: 0.9687\n",
      "[[ 0.00714685 -0.01061977 -0.04332612 ... -0.01478454  0.04794068\n",
      "  -0.03677227]\n",
      " [-0.23071742  0.2986801  -0.10573894 ...  0.08769035  0.11357135\n",
      "   0.08303021]\n",
      " [ 0.26926363  0.14236975  0.42146704 ... -0.16885625  0.38207504\n",
      "   0.18112388]\n",
      " ...\n",
      " [-0.16893771  0.16441053  0.15540835 ...  0.1937654   0.14275716\n",
      "   0.19773583]\n",
      " [-0.06138138  0.22471967  0.21549143 ...  0.33383933  0.17223884\n",
      "  -0.18794326]\n",
      " [ 0.04554403  0.00508648 -0.01926322 ... -0.02646342  0.01527454\n",
      "   0.01926715]]\n"
     ]
    }
   ],
   "source": [
    "books = fetch_data()\n",
    "\n",
    "training_text = books[0] #+ books[1] + books[2] + books[3] + books[4] + books[5]\n",
    "validation_text = books[6]\n",
    "test_text = books[7]\n",
    "\n",
    "#basic_encoder = BasicEncoder(training_text)\n",
    "#byte_pair_encoder = BytePairEncoder(training_text, 200)\n",
    "encoder = WordEncoder(training_text)\n",
    "#print(encoder.get_size())\n",
    "\n",
    "#embedder = tf.keras.layers.Embedding(encoder.get_size(), encoder.get_size(), embeddings_initializer = 'identity', trainable = False)\n",
    "\n",
    "w2v_seq_length = 10\n",
    "w2v_embedding_dim = 128\n",
    "w2v_weights = get_w2v_weights(training_text, w2v_seq_length, encoder, w2v_embedding_dim, window_size = 2, n_neg_samples = 4, batch_size = 1024, buffer_size = 10000)\n",
    "embedder = tf.keras.layers.Embedding(encoder.get_size(), w2v_embedding_dim, weights = w2v_weights, trainable = False)\n",
    "\n",
    "spelling_dictionary = get_dictionary(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlS6ITj4PQeO"
   },
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    seq_length = 100,\n",
    "    batch_size = 64,\n",
    "    buffer_size = 10000,\n",
    "    K = encoder.get_size(),\n",
    "    m = 256,\n",
    "    epochs=20,\n",
    "    learning_rate=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6HyPgFo7A5C"
   },
   "outputs": [],
   "source": [
    "training_batches = batch_data(training_text, configs[\"seq_length\"], encoder, embedder, configs[\"batch_size\"], configs[\"buffer_size\"])\n",
    "#validation_batches = batch_data_one_hot(validation_text, configs[\"seq_length\"], basic_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7axRLJIGUmS"
   },
   "outputs": [],
   "source": [
    "class SpellChecker(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs = None):\n",
    "    start = tf.constant(['.'])\n",
    "    length = 1000\n",
    "    print(\"\\nCorrectly spelled (T = 1.0):\", correctly_spelled(generate_text_temperature(start, length, self.model, basic_encoder, T = 1.0), spelling_dictionary))\n",
    "    print(\"Correctly spelled (theta = 1.0):\", correctly_spelled(generate_text_nucleus(start, length, self.model, basic_encoder, theta = 1.0), spelling_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrapNjmXRiNP",
    "outputId": "eb8453a5-4c50-4dff-d0be-420663d3cdc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 67s 2s/step - loss: 5.7480\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 64s 2s/step - loss: 4.2062\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 65s 2s/step - loss: 4.1179\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 67s 2s/step - loss: 4.0174\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.8562\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 69s 2s/step - loss: 3.7158\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 69s 2s/step - loss: 3.6373\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 72s 3s/step - loss: 3.5937\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 69s 2s/step - loss: 3.5605\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 69s 2s/step - loss: 3.5338\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.5100\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.4848\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 73s 3s/step - loss: 3.4633\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.4429\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 68s 2s/step - loss: 3.4244\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 69s 2s/step - loss: 3.4057\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.3897\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 72s 3s/step - loss: 3.3723\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.3574\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 70s 2s/step - loss: 3.3426\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(K = configs[\"K\"], m = configs[\"m\"])\n",
    "model.compile(optimizer = tf.optimizers.Adam(learning_rate = configs[\"learning_rate\"]), loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True))\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)\n",
    "\n",
    "history = model.fit(training_batches, epochs = configs[\"epochs\"], callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469,
     "referenced_widgets": [
      "305e082a71c6400887a6e289a054aa46",
      "a9b391e0de2341b9b3050a33479427fe",
      "c57e1da094bf45d38bcc2c60c0505c43",
      "4d712e63927049aa8b85d6e1e75bae89",
      "3136f431a66f48ca8c2856304767fd84",
      "0d558c78b864401f9c715b7d1e9896c3",
      "352d7394325c41fb8d12fb3a4da69f22",
      "b0674041d89b481f8f3b7b72678c14e4"
     ]
    },
    "id": "7d5Sbie5UkFQ",
    "outputId": "bc91d09c-fcab-4eb6-c7f5-9f99c25297bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2duzitr6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305e082a71c6400887a6e289a054aa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-lion-16</strong> at: <a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/2duzitr6' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/runs/2duzitr6</a><br/> View project at: <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240514_131640-2duzitr6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2duzitr6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20240514_131749-wnrjtgd1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/wnrjtgd1' target=\"_blank\">amber-sun-17</a></strong> to <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eirasorg/ProjectDD2424' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eirasorg/ProjectDD2424/runs/wnrjtgd1' target=\"_blank\">https://wandb.ai/eirasorg/ProjectDD2424/runs/wnrjtgd1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - ETA: 0s - loss: 3.2170\n",
      "Correctly spelled (T = 1.0): 0.07142857142857142\n",
      "Correctly spelled (T = 0.75): 0.1674641148325359\n",
      "Correctly spelled (T = 0.5): 0.24705882352941178\n",
      "Correctly spelled (theta = 1.0): 0.09333333333333334\n",
      "Correctly spelled (theta = 0.75): 0.09696969696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly spelled (theta = 0.5): 0.23983739837398374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<__main__.LSTM object at 0x7d2a5fe5b4c0> has the same name 'LSTM' as a built-in Keras object. Consider renaming <class '__main__.LSTM'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20240514_131749-wnrjtgd1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "72/72 [==============================] - 259s 4s/step - loss: 3.2170 - val_loss: 3.0348\n"
     ]
    }
   ],
   "source": [
    "\"\"\"wandb.init(\n",
    "        project=\"ProjectDD2424\",\n",
    "        config=configs)\n",
    "\n",
    "config=wandb.config\n",
    "\n",
    "model = LSTM(K = config.K, m = config.m)\n",
    "model.compile(optimizer = tf.optimizers.Adam(learning_rate = config.learning_rate), loss = tf.losses.SparseCategoricalCrossentropy(from_logits = True))\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)\n",
    "\n",
    "history = model.fit(training_batches, epochs = config.epochs, callbacks = [checkpoint_callback, SpellChecker(),wandb.keras.WandbCallback()], validation_data = validation_batches)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsfPjr1cmIBL",
    "outputId": "9336305a-1daa-411e-fad6-5383bbdaa638"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/n8/_26t9s310m58_t5lx9v_qd3m0000gn/T/ipykernel_21204/3002542459.py\", line 24, in __call__  *\n        A = tf.linalg.matvec(self.W, H) + tf.linalg.matvec(self.U, X[t,:]) + self.b\n\n    ValueError: slice index 1 of dimension 0 out of bounds. for '{{node strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=2, ellipsis_mask=0, end_mask=2, new_axis_mask=0, shrink_axis_mask=1](X, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)' with input shapes: [1,1,76], [2], [2], [2] and with computed input tensors: input[1] = <1 0>, input[2] = <2 0>, input[3] = <1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_temperature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrectly spelled:\u001b[39m\u001b[38;5;124m\"\u001b[39m, correctly_spelled(text, spelling_dictionary))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m, in \u001b[0;36mgenerate_text_temperature\u001b[0;34m(start, length, model, encoder, embedder, T)\u001b[0m\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m embedder(np\u001b[38;5;241m.\u001b[39mexpand_dims(encoder\u001b[38;5;241m.\u001b[39mtext_to_inds(start), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[0;32m----> 6\u001b[0m   logits, states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m/\u001b[39mT\n\u001b[1;32m      8\u001b[0m   pred \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mcategorical(logits, num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vscode_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/n8/_26t9s310m58_t5lx9v_qd3m0000gn/T/__autograph_generated_file6hxffjwt.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, X, states)\u001b[0m\n\u001b[1;32m     52\u001b[0m P \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m H \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/n8/_26t9s310m58_t5lx9v_qd3m0000gn/T/__autograph_generated_file6hxffjwt.py:42\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.if_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m A \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m t \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterate_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m P \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mstack, ([ag__\u001b[38;5;241m.\u001b[39mld(Ps)[ag__\u001b[38;5;241m.\u001b[39mld(t)] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mrange\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(seq_length),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)], \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/n8/_26t9s310m58_t5lx9v_qd3m0000gn/T/__autograph_generated_file6hxffjwt.py:35\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.if_body.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m H\n\u001b[1;32m     34\u001b[0m t \u001b[38;5;241m=\u001b[39m itr\n\u001b[0;32m---> 35\u001b[0m A \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatvec, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mW, ag__\u001b[38;5;241m.\u001b[39mld(H)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatvec, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mU, \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mb\n\u001b[1;32m     36\u001b[0m H \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mtanh, (ag__\u001b[38;5;241m.\u001b[39mld(A),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     37\u001b[0m O \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatvec, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mV, ag__\u001b[38;5;241m.\u001b[39mld(H)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mc\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/n8/_26t9s310m58_t5lx9v_qd3m0000gn/T/ipykernel_21204/3002542459.py\", line 24, in __call__  *\n        A = tf.linalg.matvec(self.W, H) + tf.linalg.matvec(self.U, X[t,:]) + self.b\n\n    ValueError: slice index 1 of dimension 0 out of bounds. for '{{node strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=2, ellipsis_mask=0, end_mask=2, new_axis_mask=0, shrink_axis_mask=1](X, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)' with input shapes: [1,1,76], [2], [2], [2] and with computed input tensors: input[1] = <1 0>, input[2] = <2 0>, input[3] = <1 1>.\n"
     ]
    }
   ],
   "source": [
    "start = '.'\n",
    "length = 1000\n",
    "T = 1.0\n",
    "\n",
    "text = generate_text_temperature(start, length, model, encoder, embedder, T)\n",
    "print(\"Correctly spelled:\", correctly_spelled(text, spelling_dictionary))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esn0xmEwWqgd",
    "outputId": "1aa34fe5-4270-468d-da37-f4fb94cc4a52"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'byte_pair_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m text \u001b[38;5;241m=\u001b[39m generate_text_temperature(start, length, model, \u001b[43mbyte_pair_encoder\u001b[49m, one_hot_embedder, T)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrectly spelled:\u001b[39m\u001b[38;5;124m\"\u001b[39m, correctly_spelled(text, spelling_dictionary))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'byte_pair_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "start = '.'\n",
    "length = 1000\n",
    "T = 1.0\n",
    "\n",
    "text = generate_text_temperature(start, length, model, byte_pair_encoder, one_hot_embedder, T)\n",
    "print(\"Correctly spelled:\", correctly_spelled(text, spelling_dictionary))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d558c78b864401f9c715b7d1e9896c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "305e082a71c6400887a6e289a054aa46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9b391e0de2341b9b3050a33479427fe",
       "IPY_MODEL_c57e1da094bf45d38bcc2c60c0505c43"
      ],
      "layout": "IPY_MODEL_4d712e63927049aa8b85d6e1e75bae89"
     }
    },
    "3136f431a66f48ca8c2856304767fd84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "352d7394325c41fb8d12fb3a4da69f22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d712e63927049aa8b85d6e1e75bae89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9b391e0de2341b9b3050a33479427fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3136f431a66f48ca8c2856304767fd84",
      "placeholder": "​",
      "style": "IPY_MODEL_0d558c78b864401f9c715b7d1e9896c3",
      "value": "0.011 MB of 0.011 MB uploaded\r"
     }
    },
    "b0674041d89b481f8f3b7b72678c14e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c57e1da094bf45d38bcc2c60c0505c43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_352d7394325c41fb8d12fb3a4da69f22",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0674041d89b481f8f3b7b72678c14e4",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

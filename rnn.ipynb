{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUiReAcd2zia2tOwLcEsyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annamaartensson/dd2424project/blob/issue%2F2b/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cpTRhWbe5_oh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "  def __init__(self, eta, grads_acc):\n",
        "    self.eta = eta\n",
        "    self.grads_acc = grads_acc\n",
        "\n",
        "  def step(self, field, grads):\n",
        "    tf.clip_by_value(getattr(grads, field), clip_value_min = -5, clip_value_max = 5)\n",
        "    getattr(self.grads_acc, field).assign(getattr(self.grads_acc, field) + tf.math.square(getattr(grads, field)))\n",
        "    return -self.eta*tf.math.divide(getattr(grads, field), tf.math.sqrt(getattr(self.grads_acc, field)+1e-8))"
      ],
      "metadata": {
        "id": "G4z1VJQXVmy4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sE6UiXiA41_c"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "\n",
        "  class Grads:\n",
        "\n",
        "    def __init__(self, m, K):\n",
        "      self.b = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "      self.c = tf.Variable(tf.zeros_initializer()(shape = (K)))\n",
        "      self.U = tf.Variable(tf.zeros_initializer()(shape = (m, K)))\n",
        "      self.W = tf.Variable(tf.zeros_initializer()(shape = (m, m)))\n",
        "      self.V = tf.Variable(tf.zeros_initializer()(shape = (K, m)))\n",
        "\n",
        "    def compute(self):\n",
        "      pass\n",
        "\n",
        "  def __init__(self, data, seq_length, m, K, sig):\n",
        "    self.data = data\n",
        "    self.seq_length = seq_length\n",
        "    self.m = m\n",
        "    self.K = K\n",
        "    self.b = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "    self.c = tf.Variable(tf.zeros_initializer()(shape = (K)))\n",
        "    self.U = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (m, K)))\n",
        "    self.W = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (m, m)))\n",
        "    self.V = tf.Variable(tf.random_normal_initializer(mean=0.0, stddev=sig)(shape = (K, m)))\n",
        "    self.hprev = tf.Variable(tf.zeros_initializer()(shape = (m)))\n",
        "\n",
        "  def forwardPass(self, X, Y):\n",
        "      P = tf.Variable(tf.zeros_initializer()(shape = (self.K, self.seq_length)))\n",
        "      H = tf.Variable(tf.zeros_initializer()(shape = (self.m, self.seq_length+1)))\n",
        "      A = tf.Variable(tf.zeros_initializer()(shape = (self.m, self.seq_length)))\n",
        "      H[:,0].assign(self.h0)\n",
        "      for t in range(self.seq_length):\n",
        "        A[:,t].assign(tf.tensordot(self.W, H[:,t], 1) + tf.tensordot(self.U, X[:,t], 1) + self.b)\n",
        "        H[:,t+1].assign(tf.math.tanh(A[:,t]))\n",
        "        P[:,t].assign(tf.raw_ops.Softmax(logits = (tf.tensordot(self.V, H[:,t+1], 1) + self.c)))\n",
        "      return P, H, A\n",
        "\n",
        "  def backwardPass(self, X, Y, P, H, A):\n",
        "    grads = RNN.Grads(self.m, self.K)\n",
        "\n",
        "    G = tf.transpose(Y-P) * -1\n",
        "\n",
        "    #dL/dc\n",
        "    grads.c.assign(tf.reduce_sum(G, axis=0))\n",
        "\n",
        "    #dL/dV\n",
        "    for i in range(self.seq_length):\n",
        "      grads.V.assign(grads.V+tf.tensordot(G[i,:],H[:,i],0))\n",
        "\n",
        "    #dL/dh and dL/da, in grad_H and grad_A each row represents a timestep\n",
        "    grad_H = tf.Variable(tf.zeros_initializer()(shape = (self.seq_length, self.m)))\n",
        "    grad_A = tf.Variable(tf.zeros_initializer()(shape = (self.seq_length, self.m)))\n",
        "    grad_H[-1,:].assign(tf.tensordot(tf.reshape(G[-1,:], (1,-1)),self.V,1))\n",
        "    for i in range(self.seq_length):\n",
        "      grad_A[-i,:].assign(tf.tensordot(tf.reshape(grad_H[-i,:],(1,-1)),tf.linalg.diag(tf.ones(self.m)-tf.math.square(tf.math.tanh(A[:,-i]))),1))\n",
        "      grad_H[-i-1,:].assign(tf.tensordot(tf.reshape(G[-i-1,:], (1,-1)),self.V,1)+tf.tensordot(tf.reshape(grad_A[-i,:], (1,-1)),self.W,1))\n",
        "    grad_A[0,:].assign(tf.tensordot(tf.reshape(grad_H[0,:],(1,-1)),tf.linalg.diag(tf.ones(self.m)-tf.math.square(tf.math.tanh(A[:,0]))),1))\n",
        "\n",
        "    #dL/db\n",
        "    grads.b.assign(tf.reduce_sum(grad_A, axis=0))\n",
        "\n",
        "    #dL/dW\n",
        "    for i in range(self.seq_length):\n",
        "      grads.W.assign(grads.W+tf.tensordot(grad_A[i,:],H[:,i],0))\n",
        "\n",
        "    #dL/dU\n",
        "    for i in range(self.seq_length):\n",
        "      grads.U.assign(grads.U+tf.tensordot(grad_A[i,:],X[:,i],0))\n",
        "\n",
        "    return grads\n",
        "\n",
        "  def loss(self, Y, P):\n",
        "    L = 0\n",
        "    for t in range(self.seq_length):\n",
        "        L -= tf.tensordot(Y[:,t], tf.math.log(P[:,t]), 1)\n",
        "    return L\n",
        "\n",
        "  def train(self, eta, steps):\n",
        "    e = 0\n",
        "    grads_acc = RNN.Grads(self.m, self.K)\n",
        "    optimizer = AdaGrad(eta, grads_acc)\n",
        "    for iter in range(steps):\n",
        "      X = self.data[:,e:e+self.seq_length]\n",
        "      Y = self.data[:,e+1:e+self.seq_length+2]\n",
        "      P, H, A = self.forwardPass(X)\n",
        "      L = self.loss(Y, P)\n",
        "      print(f\"iter = {iter}, loss = {L}\")\n",
        "      grads = self.backwardPass(X, Y, P, H, A)\n",
        "      for field in vars(grads):\n",
        "        getattr(self, field).assign(getattr(self, field)+optimizer.step(field, grads))\n",
        "      e = e+1\n",
        "      if e > len(self.data)-self.seq_length-2:\n",
        "        e = 0\n",
        "        self.hprev.assign(tf.zeros((m)))\n",
        "      else:\n",
        "        self.hprev.assign(H[:,self.seq_length])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path_to_file = tf.keras.utils.get_file('prideandprejudice.txt', 'https://www.gutenberg.org/cache/epub/42671/pg42671.txt')\n",
        "#text = list(open(path_to_file, 'rb').read().decode(encoding='utf-8'))\n",
        "text = list(open('goblet_book.txt', 'rb').read().decode(encoding='utf-8'))\n"
      ],
      "metadata": {
        "id": "znWk0L0lUW0X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = sorted(set(text))\n",
        "char_to_ind = tf.keras.layers.StringLookup(vocabulary = list(vocabulary), mask_token = None)\n",
        "ind_to_char = tf.keras.layers.StringLookup(vocabulary = char_to_ind.get_vocabulary(), invert = True, mask_token = None)"
      ],
      "metadata": {
        "id": "PkI1dzQAUwgl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 25\n",
        "m = 100\n",
        "K = len(vocabulary)\n",
        "sig = 0.01\n",
        "data = tf.transpose(tf.one_hot(char_to_ind(text), K))"
      ],
      "metadata": {
        "id": "LemQgxO8lUR-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(data, seq_length, m, K, sig)\n",
        "rnn.train(0.1, 10)\n",
        "#X = data[:,0:seq_length]\n",
        "#Y = data[:,1:seq_length+1]\n",
        "#P, H, A = rnn.forwardPass(X)\n",
        "#print(rnn.loss(Y, P))"
      ],
      "metadata": {
        "id": "BHGj2DtRl1iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ef4580-4eae-491e-c3aa-f8b7b7f683c2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter = 0, loss = 109.54740142822266\n",
            "iter = 1, loss = 109.54781341552734\n",
            "iter = 2, loss = 109.54824829101562\n",
            "iter = 3, loss = 109.54658508300781\n",
            "iter = 4, loss = 109.54887390136719\n",
            "iter = 5, loss = 109.5482177734375\n",
            "iter = 6, loss = 109.54767608642578\n",
            "iter = 7, loss = 109.54552459716797\n",
            "iter = 8, loss = 109.54651641845703\n",
            "iter = 9, loss = 109.54473114013672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 1e-8\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP1k7eWdSyiR",
        "outputId": "0548b89f-1121-4e63-9366-610eef47f158"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'float'>\n"
          ]
        }
      ]
    }
  ]
}